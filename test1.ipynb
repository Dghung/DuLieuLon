{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb1e5919",
   "metadata": {
    "id": "bb1e5919",
    "outputId": "782c6e00-afd4-4221-bbf9-c7ca057cbfdc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/26 22:59:38 WARN Utils: Your hostname, DuLieuLonUbuntu, resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "25/12/26 22:59:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/26 23:00:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark HDFS Jupyter</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x77c8e92049e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark HDFS Jupyter\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eDtevm39RuE",
   "metadata": {
    "id": "6eDtevm39RuE"
   },
   "source": [
    "# Xử lí dữ liệu\n",
    "## Tải dữ liệu lên HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01622c1",
   "metadata": {
    "id": "c01622c1",
    "outputId": "e4a1469a-24e9-4c20-9649-a3c94a8f7fc8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+-----------------+\n",
      "|               title|                text|subject|             date|\n",
      "+--------------------+--------------------+-------+-----------------+\n",
      "| Donald Trump Sen...|Donald Trump just...|   News|December 31, 2017|\n",
      "| Drunk Bragging T...|House Intelligenc...|   News|December 31, 2017|\n",
      "| Sheriff David Cl...|On Friday, it was...|   News|December 30, 2017|\n",
      "| Trump Is So Obse...|On Christmas day,...|   News|December 29, 2017|\n",
      "| Pope Francis Jus...|Pope Francis used...|   News|December 25, 2017|\n",
      "+--------------------+--------------------+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "+--------------------+--------------------+------------+------------------+\n",
      "|               title|                text|     subject|              date|\n",
      "+--------------------+--------------------+------------+------------------+\n",
      "|As U.S. budget fi...|WASHINGTON (Reute...|politicsNews|December 31, 2017 |\n",
      "|U.S. military to ...|WASHINGTON (Reute...|politicsNews|December 29, 2017 |\n",
      "|Senior U.S. Repub...|WASHINGTON (Reute...|politicsNews|December 31, 2017 |\n",
      "|FBI Russia probe ...|WASHINGTON (Reute...|politicsNews|December 30, 2017 |\n",
      "|Trump wants Posta...|SEATTLE/WASHINGTO...|politicsNews|December 29, 2017 |\n",
      "+--------------------+--------------------+------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "path_fake = \"hdfs://localhost:9000/user/hdoop/newsdata/Fake.csv\"\n",
    "path_true = \"hdfs://localhost:9000/user/hdoop/newsdata/True.csv\"\n",
    "\n",
    "df_fake = spark.read.csv(path_fake, header=True, inferSchema=True)\n",
    "df_true = spark.read.csv(path_true, header=True, inferSchema=True)\n",
    "\n",
    "df_fake.show(5)\n",
    "df_true.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R48X8ouo9epF",
   "metadata": {
    "id": "R48X8ouo9epF"
   },
   "source": [
    "## Gán label true = 1, fake = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05150fec",
   "metadata": {
    "id": "05150fec",
    "outputId": "f547f791-cc03-4d42-e2d2-8a02ca3a38f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23489"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df_fake = df_fake.withColumn(\"label\", lit(0))\n",
    "df_true = df_true.withColumn(\"label\", lit(1))\n",
    "\n",
    "data = df_fake.union(df_true)\n",
    "\n",
    "df_fake.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9726578",
   "metadata": {
    "id": "f9726578",
    "outputId": "99d5a31d-6c01-43c2-fe7f-fdbc476e89e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+-----------------+-----+\n",
      "|               title|                text|subject|             date|label|\n",
      "+--------------------+--------------------+-------+-----------------+-----+\n",
      "| Donald Trump Sen...|Donald Trump just...|   News|December 31, 2017|    0|\n",
      "| Drunk Bragging T...|House Intelligenc...|   News|December 31, 2017|    0|\n",
      "| Sheriff David Cl...|On Friday, it was...|   News|December 30, 2017|    0|\n",
      "| Trump Is So Obse...|On Christmas day,...|   News|December 29, 2017|    0|\n",
      "| Pope Francis Jus...|Pope Francis used...|   News|December 25, 2017|    0|\n",
      "+--------------------+--------------------+-------+-----------------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064db5f",
   "metadata": {
    "id": "b064db5f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "anNMMOUF91bg",
   "metadata": {
    "id": "anNMMOUF91bg"
   },
   "source": [
    "### Xóa dòng có dữ liệu NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa98014",
   "metadata": {
    "id": "faa98014",
    "outputId": "4a799d1e-62e8-4eb1-9751-e9204cf6004b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------+----+-----+\n",
      "|title|text|subject|date|label|\n",
      "+-----+----+-------+----+-----+\n",
      "|    0|   8|      8|   8|    0|\n",
      "+-----+----+-------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, col, count, when\n",
    "\n",
    "data.select([count(when(col(c).isNull(), c)).alias(c) for c in data.columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ef60e",
   "metadata": {
    "id": "399ef60e",
    "outputId": "5d0a5d49-034c-4b27-b361-ab9cc8cbb38f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[title: string, text: string, subject: string, date: string, label: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4430d",
   "metadata": {
    "id": "76b4430d",
    "outputId": "e49fbc4d-f22c-4343-d831-7b9b96bcfdfc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44906"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba4c28",
   "metadata": {
    "id": "cfba4c28",
    "outputId": "14c5c05d-724a-48ab-dbee-3ecd8d70789a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- subject: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44466"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "data.printSchema()\n",
    "\n",
    "data_safe = data.filter(col(\"text\").isNotNull())\n",
    "\n",
    "data_safe.count()\n",
    "\n",
    "data = data_safe.dropDuplicates()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "INOjaL4b-AxE",
   "metadata": {
    "id": "INOjaL4b-AxE"
   },
   "source": [
    "### Làm sạch dữ liệu(loại bỏ tên trang báo và khu vực ở đầu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0290472",
   "metadata": {
    "id": "a0290472",
    "outputId": "d3b05b0d-0ed1-4af9-9fd5-885556be95ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Mẫu dữ liệu sau khi làm sạch Dateline ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                text|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|Republicans could hold onto control of Virginia’s legislature after a race that had appeared to c...|\n",
      "|Michigan Governor Rick Snyder said on Friday the state would hold a special election on Nov. 6, 2...|\n",
      "|U.S. Special Counsel Robert Mueller’s office has spent about $3.2 million in the first 4-1/2 mont...|\n",
      "|President Donald Trump’s 90 percent cut to Obamacare advertising has U.S. health insurers in many...|\n",
      "|President Donald Trump will announce next week his choice for who will lead the Federal Reserve, ...|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace, col, trim\n",
    "\n",
    "# Giải thích Regex:\n",
    "# ^          : Bắt đầu dòng\n",
    "# .*?        : Bất kỳ ký tự nào (Tên thành phố, bang...)\n",
    "# \\(.*?\\)    : Nội dung trong ngoặc đơn (Tên hãng tin bất kỳ)\n",
    "# \\s*-\\s* : Dấu gạch ngang ngăn cách\n",
    "# Ví dụ sẽ khớp: \"WASHINGTON (Reuters) - \" hoặc \"NEW YORK/LONDON (AP) - \"\n",
    "robust_pattern = r\"^.*?\\s*\\(.*?\\)\\s*-\\s*\"\n",
    "\n",
    "# Thực hiện xóa\n",
    "data_clean_text = data.withColumn(\"text\", regexp_replace(col(\"text\"), robust_pattern, \"\"))\n",
    "data_clean_text = data_clean_text.withColumn(\"text\", trim(col(\"text\")))\n",
    "\n",
    "# Kiểm tra kết quả\n",
    "print(\"--- Mẫu dữ liệu sau khi làm sạch Dateline ---\")\n",
    "data_clean_text.filter(\"label = 1\").select(\"text\").show(5, truncate=100)\n",
    "data = data_clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1242eed",
   "metadata": {
    "id": "e1242eed",
    "outputId": "92e61fe7-b2dc-434b-e8cd-164f5740673f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[title: string, text: string, subject: string, date: string, label: int]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SKTRfzfx-Or1",
   "metadata": {
    "id": "SKTRfzfx-Or1"
   },
   "source": [
    "# Test mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76654b5c",
   "metadata": {
    "id": "76654b5c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NrG_j4Xy_Q14",
   "metadata": {
    "id": "NrG_j4Xy_Q14"
   },
   "source": [
    "### Tiền sử lí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896893d3",
   "metadata": {
    "id": "896893d3",
    "outputId": "d8231109-436e-4e22-942e-280f069bcf15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                              text|                                             words|                                    filtered_words|\n",
      "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "|This maniac wants  The Handmaid s Tale  to beco...|[this, maniac, wants, the, handmaid, s, tale, t...|[maniac, wants, handmaid, tale, become, reality...|\n",
      "|West Virginia is solid Trump country. The argum...|[west, virginia, is, solid, trump, country, the...|[west, virginia, solid, trump, country, argumen...|\n",
      "|President Donald Trump has had some strong word...|[president, donald, trump, has, had, some, stro...|[president, donald, trump, strong, words, fierc...|\n",
      "|Earlier today, Donald Trump once again disgrace...|[earlier, today, donald, trump, once, again, di...|[earlier, today, donald, trump, disgraced, unit...|\n",
      "|If Donald Trump drags us into war with North Ko...|[if, donald, trump, drags, us, into, war, with,...|[donald, trump, drags, us, war, north, korea, w...|\n",
      "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W+\")\n",
    "\n",
    "data_tokenized = regex_tokenizer.transform(data)\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "data_cleaned = remover.transform(data_tokenized)\n",
    "\n",
    "data_cleaned.select(\"text\", \"words\", \"filtered_words\").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ac81b",
   "metadata": {
    "id": "e85ac81b",
    "outputId": "9562b3b5-539a-4e55-8f8e-74bfe8d4363e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------------------------------------------+-------+------------------+-----+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                             title|                                              text|subject|              date|label|                                             words|                                    filtered_words|\n",
      "+--------------------------------------------------+--------------------------------------------------+-------+------------------+-----+--------------------------------------------------+--------------------------------------------------+\n",
      "| WATCH: Republican Lawmaker Claims Forcing Wome...|This maniac wants  The Handmaid s Tale  to beco...|   News|  November 6, 2017|    0|[this, maniac, wants, the, handmaid, s, tale, t...|[maniac, wants, handmaid, tale, become, reality...|\n",
      "| W. Virginia Halloween Store Boasts Shockingly ...|West Virginia is solid Trump country. The argum...|   News|  October 19, 2017|    0|[west, virginia, is, solid, trump, country, the...|[west, virginia, solid, trump, country, argumen...|\n",
      "| Trump Is So Bad Hillary Is Telling Him How To ...|President Donald Trump has had some strong word...|   News|September 27, 2017|    0|[president, donald, trump, has, had, some, stro...|[president, donald, trump, strong, words, fierc...|\n",
      "| Defense Secretary Mattis Speaks Over Incompete...|Earlier today, Donald Trump once again disgrace...|   News| September 3, 2017|    0|[earlier, today, donald, trump, once, again, di...|[earlier, today, donald, trump, disgraced, unit...|\n",
      "| Trump STUPIDLY Attacks A Major U.S. Ally Befor...|If Donald Trump drags us into war with North Ko...|   News| September 3, 2017|    0|[if, donald, trump, drags, us, into, war, with,...|[donald, trump, drags, us, war, north, korea, w...|\n",
      "+--------------------------------------------------+--------------------------------------------------+-------+------------------+-----+--------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "data_cleaned.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XDguiDHb_w6F",
   "metadata": {
    "id": "XDguiDHb_w6F"
   },
   "source": [
    "Dùng kỹ thuật TF-IDF (Term Frequency - Inverse Document Frequency).\n",
    "\n",
    "TF (HashingTF): Đếm tần suất xuất hiện của từ trong bài viết. (Từ nào xuất hiện nhiều trong 1 bài thì quan trọng với bài đó).\n",
    "\n",
    "IDF: Đánh giá độ \"hiếm\" của từ trong toàn bộ tập dữ liệu. (Từ nào bài nào cũng có thì ít quan trọng, từ nào hiếm mới là đặc trưng)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ebd080",
   "metadata": {
    "id": "45ebd080",
    "outputId": "0a728dc9-01df-46cb-f644-8a0dccdbc7ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                    filtered_words|                                          features|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|[maniac, wants, handmaid, tale, become, reality...|(10000,[148,217,291,320,353,379,391,398,453,503...|\n",
      "|[west, virginia, solid, trump, country, argumen...|(10000,[80,157,366,452,461,488,608,649,659,665,...|\n",
      "|[president, donald, trump, strong, words, fierc...|(10000,[35,132,141,157,223,366,387,452,524,548,...|\n",
      "|[earlier, today, donald, trump, disgraced, unit...|(10000,[94,132,366,429,452,479,505,533,673,688,...|\n",
      "|[donald, trump, drags, us, war, north, korea, w...|(10000,[12,132,224,366,383,419,452,613,666,743,...|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "featurized_data = hashingTF.transform(data_cleaned)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idf_model = idf.fit(featurized_data)\n",
    "\n",
    "final_data = idf_model.transform(featurized_data)\n",
    "\n",
    "final_data.select(\"filtered_words\", \"features\").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89434954",
   "metadata": {
    "id": "89434954"
   },
   "source": [
    "# su dung Logistic Regression kiểm tra mô hình\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671222d",
   "metadata": {
    "id": "c671222d",
    "outputId": "7e6b6d06-0650-4234-84a7-15b1ae80311d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|16966|\n",
      "|    0|18552|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 2102|\n",
      "|    0| 2343|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 2143|\n",
      "|    0| 2360|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "train_data, val_data, test_data = final_data.randomSplit([0.8, 0.1, 0.1], seed=42)\n",
    "\n",
    "train_data.groupby(\"label\").count().show()\n",
    "val_data.groupby(\"label\").count().show()\n",
    "test_data.groupby(\"label\").count().show()\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3f07f",
   "metadata": {
    "id": "aca3f07f",
    "outputId": "0702aa33-360b-4ad5-8cbc-15e5e8d1beea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|            features|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|    0|(10000,[70,132,42...|       0.0|\n",
      "|    0|(10000,[7,43,47,5...|       0.0|\n",
      "|    0|(10000,[7,132,201...|       0.0|\n",
      "|    1|(10000,[15,87,108...|       1.0|\n",
      "|    1|(10000,[1,14,132,...|       1.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "predictions.select(\"label\", \"features\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3766a14",
   "metadata": {
    "id": "f3766a14",
    "outputId": "8c02c067-95d1-4e4e-c7bb-638121722436"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.9704641350210971\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7544211",
   "metadata": {
    "id": "a7544211",
    "outputId": "558bce6f-1e2d-40fd-afae-786d8544818d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 97.05%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy = {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RRWaQiYQ_5ui",
   "metadata": {
    "id": "RRWaQiYQ_5ui"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "DcTPa1eOAFbT",
   "metadata": {
    "id": "DcTPa1eOAFbT"
   },
   "source": [
    "# Tạo Pipiline đưa dữ liệu và train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a951c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+------------------+-----+\n",
      "|               title|                text|subject|              date|label|\n",
      "+--------------------+--------------------+-------+------------------+-----+\n",
      "| WATCH: Republica...|This maniac wants...|   News|  November 6, 2017|    0|\n",
      "| W. Virginia Hall...|West Virginia is ...|   News|  October 19, 2017|    0|\n",
      "| Trump Is So Bad ...|President Donald ...|   News|September 27, 2017|    0|\n",
      "| Defense Secretar...|Earlier today, Do...|   News| September 3, 2017|    0|\n",
      "| Trump STUPIDLY A...|If Donald Trump d...|   News| September 3, 2017|    0|\n",
      "+--------------------+--------------------+-------+------------------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "data_clean_text.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb230fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+------------------+-----+\n",
      "|               title|                text|subject|              date|label|\n",
      "+--------------------+--------------------+-------+------------------+-----+\n",
      "| WATCH: Republica...|This maniac wants...|   News|  November 6, 2017|    0|\n",
      "| W. Virginia Hall...|West Virginia is ...|   News|  October 19, 2017|    0|\n",
      "| Trump Is So Bad ...|President Donald ...|   News|September 27, 2017|    0|\n",
      "| Defense Secretar...|Earlier today, Do...|   News| September 3, 2017|    0|\n",
      "| Trump STUPIDLY A...|If Donald Trump d...|   News| September 3, 2017|    0|\n",
      "+--------------------+--------------------+-------+------------------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38aa5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "train_data, val_data, test_data = data.randomSplit([0.8, 0.1, 0.1], seed=42)\n",
    "\n",
    "# 1. Các bước cũ\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W+\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. Tạo N-Grams (Ghép 2 từ liền nhau)\n",
    "ngram = NGram(n=2, inputCol=\"filtered_words\", outputCol=\"bigrams\")\n",
    "\n",
    "# 3. HasingTF\n",
    "hashingTF = HashingTF(inputCol=\"bigrams\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# 4. Pipeline mới\n",
    "pipeline = Pipeline(stages=[regexTokenizer, remover, ngram, hashingTF, idf, lr])\n",
    "\n",
    "# 5. Train lại và Lưu lại model\n",
    "pipeline_model = pipeline.fit(train_data)\n",
    "pipeline_model.write().overwrite().save(\"hdfs://localhost:9000/user/hdoop/fake_news_model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0380113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data - Accuracy: 100.00%, F1 Score: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       0.0|18552|\n",
      "|    1|       1.0|16965|\n",
      "|    1|       0.0|    1|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data - Accuracy: 94.89%, F1 Score: 94.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       0.0| 2242|\n",
      "|    1|       1.0| 1976|\n",
      "|    1|       0.0|  126|\n",
      "|    0|       1.0|  101|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data - Accuracy: 94.91%, F1 Score: 94.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       0.0| 2260|\n",
      "|    1|       1.0| 2014|\n",
      "|    0|       1.0|  100|\n",
      "|    1|       0.0|  129|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "def evaluate_model(data, name):\n",
    "    predictions = pipeline_model.transform(data)\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "   \n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    f1_score = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "    print(f\"{name} - Accuracy: {accuracy * 100:.2f}%, F1 Score: {f1_score * 100:.2f}%\")\n",
    "\n",
    "    predictions.groupby(\"label\", \"prediction\").count().show()\n",
    "evaluate_model(train_data, \"Train Data\")\n",
    "evaluate_model(val_data, \"Validation Data\")\n",
    "evaluate_model(test_data, \"Test Data\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
